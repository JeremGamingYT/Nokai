# ğŸ§  NÅkai (è„³æµ·) - Architecture Cognitive BiomimÃ©tique

<div align="center">

**Le Premier Cerveau Artificiel VÃ©ritablement Bio-InspirÃ©**

[![Version](https://img.shields.io/badge/version-0.3.0-blue.svg)]()
[![Python](https://img.shields.io/badge/python-3.10%2B-green.svg)]()
[![License](https://img.shields.io/badge/license-MIT-purple.svg)]()

</div>

---

## ğŸ¯ Vision

NÅkai n'est pas "un autre LLM". C'est une **Architecture Cognitive BiomimÃ©tique** qui reproduit les mÃ©canismes fondamentaux du cerveau humain :

| ProblÃ¨me des LLM Actuels | Solution NÅkai |
|-------------------------|----------------|
| ğŸ”´ **Statiques** : N'apprennent plus aprÃ¨s l'entraÃ®nement | âœ… **PlasticitÃ© Synaptique** : Apprentissage Hebbien immÃ©diat |
| ğŸ”´ **Inefficients** : 100% des poids activÃ©s (O(NÂ²)) | âœ… **Sparsity Thalamique** : 5% d'activation seulement |
| ğŸ”´ **Sans but** : Minimisation de perte statistique | âœ… **Dopamine HomÃ©ostatique** : RÃ©compense basÃ©e sur la SURPRISE |
| ğŸ”´ **Character-level** : Manipulent des lettres | âœ… **Tokenization BPE** : Comprennent des CONCEPTS |

---

## ğŸ†• v0.3.0 - L'Ã‰veil Cognitif

Cette version apporte trois amÃ©liorations majeures :

### 1. ğŸ“š Tokenization BPE (ComprÃ©hension SÃ©mantique)

```python
from nokai.tokenization import NokaiTokenizer, TokenizerConfig

# CrÃ©er et entraÃ®ner le tokenizer
tokenizer = NokaiTokenizer.train(
    texts=corpus,
    config=TokenizerConfig(vocab_size=32000)
)

# L'IA manipule maintenant des mots/concepts, pas des lettres !
tokens = tokenizer.encode("Le cerveau utilise la dopamine pour apprendre")
# â†’ [1, 534, 2891, 891, 45, 7823, 234, 892, 2]
```

**Analogie Biologique :** Le cerveau ne traite pas les lettres une par une. Il reconnaÃ®t des morphÃ¨mes (unitÃ©s de sens) et des mots entiers.

### 2. ğŸ’Š Dopamine HomÃ©ostatique (Plus jamais Ã  1.0)

```python
from nokai.limbic import DopamineCircuit

circuit = DopamineCircuit(state_dim=256)

# La dopamine se base sur la SURPRISE, pas le succÃ¨s brut
for step in range(100):
    state, meta = circuit(hidden_state, reward=constant_reward)
    print(f"DA: {state.effective_signal:.3f}, Habituation: {meta['habituation']:.3f}")
    # â†’ DA dÃ©croÃ®t vers 0.5 si la rÃ©compense est constante (homÃ©ostasie)
```

**Formule MathÃ©matique :**
```
Î´(t) = R(t) + Î³Â·V(s_{t+1}) - V(s_t)   # Reward Prediction Error
DA_effective = DA_raw - Baseline + 0.5  # Ajustement homÃ©ostatique
```

### 3. âš¡ Apprentissage Hebbien ImmÃ©diat

```python
from nokai.learning import HebbianPlasticity, HebbianConfig

hebbian = HebbianPlasticity(
    in_features=256,
    out_features=512,
    config=HebbianConfig(
        learning_rate=0.001,
        dopamine_gating=True,  # Apprend seulement si DA > 0.3
    )
)

# L'apprentissage se fait PENDANT le forward pass !
output = layer(x)
hebbian.apply_update(layer.weight, pre=x, post=output, dopamine=da_level)
```

**RÃ¨gle de Hebb :** "Les neurones qui s'activent ensemble se connectent plus fortement."

---

## ğŸ—ï¸ Architecture Neuromorphique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     NÅŒKAI NEUROMORPHIC BRAIN                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  INPUT â†’ [THALAMUS] â†’ Filtre/Route (5% sparsity)             â”‚
â”‚            â†“                                                  â”‚
â”‚  [CORTEX] â†â†’ [WORKING MEMORY] â†â†’ [HIPPOCAMPUS]              â”‚
â”‚      â†“              â†“                   â†“                    â”‚
â”‚  [SEMANTIC] â†â”€â”€ [CONSOLIDATION] â†â”€â”€ [EPISODIC]              â”‚
â”‚            â†“                                                  â”‚
â”‚  [dACC] â†’ Incertitude â†’ [ATTENTION CONTROLLER]               â”‚
â”‚            â†“                                                  â”‚
â”‚  [STRIATUM] â†â”€â”€ [DOPAMINE/VTA] â†’ SÃ©lection d'Action          â”‚
â”‚            â†“                                                  â”‚
â”‚  OUTPUT â† DÃ©cision/RÃ©ponse                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Modules ClÃ©s

| Module | RÃ©gion CÃ©rÃ©brale | Fonction |
|--------|------------------|----------|
| `ThalamusGateway` | Thalamus | Filtrage sensoriel, 5% des tokens passent |
| `Cortex` | NÃ©ocortex | Traitement hiÃ©rarchique par colonnes corticales |
| `HippocampalMemory` | Hippocampe | MÃ©moire Ã©pisodique, completion de patterns |
| `PrefrontalWorkingMemory` | Cortex PrÃ©frontal | MÃ©moire de travail, contrÃ´le exÃ©cutif |
| `DopamineCircuit` | VTA/NAc | RÃ©compense, motivation, modulation apprentissage |
| `SemanticMemory` | Neocortex | Connaissances Ã  long terme |
| `ConsolidationSystem` | - | Consolidation mÃ©moire ("sommeil") |

---

## ğŸš€ DÃ©marrage Rapide

### Installation

```bash
git clone https://github.com/JeremGamingYT/Nokai.git
cd Nokai
python -m venv .venv
.venv\Scripts\activate  # Windows
pip install -e .
pip install tokenizers datasets  # Pour BPE et donnÃ©es
```

### EntraÃ®nement Cognitif V2

```bash
# EntraÃ®nement complet avec toutes les amÃ©liorations
python scripts/train_cognitive_v2.py \
    --preset mini \
    --epochs 10 \
    --vocab_size 32000 \
    --hebbian_lr 0.001

# Options pour dÃ©sactiver des fonctionnalitÃ©s
python scripts/train_cognitive_v2.py \
    --no_hebbian           # DÃ©sactive apprentissage Hebbien
    --no_dopamine_gating   # DÃ©sactive gating dopaminergique
    --no_bpe               # Utilise tokenization caractÃ¨re
```

### Test Rapide

```bash
python scripts/test_cognitive_v2.py
```

---

## ğŸ“Š Configurations Disponibles

| Preset | ParamÃ¨tres | VRAM | Usage |
|--------|-----------|------|-------|
| `nano` | ~4M | 200MB | Tests rapides |
| `micro` | ~17M | 500MB | Prototypage |
| `mini` | ~67M | 2GB | EntraÃ®nement lÃ©ger |
| `base` | ~268M | 6GB | Production (RTX 3060+) |
| `large` | ~1B | 16GB | Haute performance |

---

## ğŸ§¬ Principes Biologiques ImplÃ©mentÃ©s

### 1. SparsitÃ© MÃ©tabolique
Le cerveau consomme 20W mais traite des informations complexes. Nous reproduisons cette efficacitÃ© :
- Seulement 5% des neurones actifs Ã  chaque instant
- `energy_check()` avant chaque module pour dÃ©cider de l'activation

### 2. PlasticitÃ© Synaptique
```
Î”w_ij = Î· Â· DA Â· (x_j Â· x_i - Î± Â· x_jÂ² Â· w_ij)
```
- **RÃ¨gle de Oja** : Normalisation pour Ã©viter l'explosion des poids
- **BCM** : Seuil glissant pour mÃ©taplasticitÃ©
- **Dopamine** : Gate l'apprentissage (pas de DA = pas d'apprentissage)

### 3. Oscillations Neurales
- **Theta (4-8 Hz)** : Coordination mÃ©moire-cortex
- **Gamma (30-100 Hz)** : Binding perceptuel
- Les oscillations modulent le traitement Ã  travers les modules

### 4. Consolidation MÃ©moire ("Sommeil")
PÃ©riodiquement, le modÃ¨le :
- Rejoue les souvenirs rÃ©cents
- TransfÃ¨re les souvenirs importants vers la mÃ©moire sÃ©mantique
- Applique l'homÃ©ostasie synaptique (downscaling)

---

## ğŸ“ Structure du Projet

```
nokai/
â”œâ”€â”€ __init__.py           # Exports principaux
â”œâ”€â”€ brain.py              # NeuromorphicBrain (intÃ©gration complÃ¨te)
â”œâ”€â”€ model.py              # NokaiModel (version simplifiÃ©e)
â”œâ”€â”€ config.py             # Configurations
â”‚
â”œâ”€â”€ cortex/               # Traitement cortical
â”‚   â”œâ”€â”€ cortex.py         # Assemblage cortical
â”‚   â””â”€â”€ column.py         # Colonnes corticales avec Hebbian
â”‚
â”œâ”€â”€ limbic/               # SystÃ¨me limbique
â”‚   â”œâ”€â”€ dopamine.py       # Circuit dopamine V1 (legacy)
â”‚   â”œâ”€â”€ dopamine_v2.py    # Circuit dopamine homÃ©ostatique âœ¨
â”‚   â”œâ”€â”€ striatum.py       # SÃ©lection d'action
â”‚   â””â”€â”€ dacc.py           # MÃ©tacognition
â”‚
â”œâ”€â”€ learning/             # RÃ¨gles d'apprentissage
â”‚   â”œâ”€â”€ hebbian.py        # Hebbien V1 (legacy)
â”‚   â”œâ”€â”€ hebbian_v2.py     # BCM + Dopamine gating âœ¨
â”‚   â””â”€â”€ predictive.py     # Codage prÃ©dictif
â”‚
â”œâ”€â”€ tokenization/         # Tokenization BPE âœ¨
â”‚   â”œâ”€â”€ bpe_tokenizer.py  # NokaiTokenizer
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ hippocampus/          # MÃ©moire Ã©pisodique
â”œâ”€â”€ memory/               # MÃ©moire sÃ©mantique + consolidation
â”œâ”€â”€ thalamus/             # Gateway d'attention
â”œâ”€â”€ prefrontal/           # MÃ©moire de travail
â”œâ”€â”€ oscillations/         # Rythmes neuraux
â””â”€â”€ attention/            # ContrÃ´le attentionnel

scripts/
â”œâ”€â”€ train_cognitive_v2.py # EntraÃ®nement avec toutes les amÃ©liorations âœ¨
â”œâ”€â”€ train_wikipedia.py    # EntraÃ®nement original
â”œâ”€â”€ test_cognitive_v2.py  # Tests des nouveaux composants
â””â”€â”€ chat.py               # Interface de gÃ©nÃ©ration
```

---

## ğŸ”¬ Prochaines Ã‰tapes

- [ ] **Predictive Coding** : ImplÃ©mentation complÃ¨te de l'apprentissage prÃ©dictif
- [ ] **Cerebellum** : Module de timing et coordination motrice
- [ ] **Multi-modal** : Extension vers vision et audio
- [ ] **Meta-Learning** : Apprendre Ã  apprendre (MAML-like biologique)

---

## ğŸ“– RÃ©fÃ©rences Biologiques

- Hebb, D.O. (1949). *The Organization of Behavior*
- Schultz, W. (1998). Predictive reward signal of dopamine neurons. *J. Neurophysiology*
- Bienenstock, E., Cooper, L., Munro, P. (1982). Theory for the development of neuron selectivity (BCM rule)
- BuzsÃ¡ki, G. (2006). *Rhythms of the Brain*

---

## ğŸ“œ Licence

MIT License - Voir [LICENSE](LICENSE)

---

<div align="center">

**NÅkai** - *L'IA qui pense comme un cerveau*

ğŸ§  Made with neuroscience

</div>
