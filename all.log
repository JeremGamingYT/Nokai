======================================================================
NÅŒKAI COGNITIVE TRAINING V2.1 - ALIGNED BRAIN
======================================================================
  Preset: nano
  BPE Tokenization: True
  Hebbian Learning: True
  Dopamine Gating: True
======================================================================

[1/5] Loading data...
  Loading from file: data/tinystories.txt
  Loaded 4991 texts from file

[2/5] Setting up tokenizer (DATA-ALIGNED)...
  Training NEW BPE tokenizer on data...
[NokaiTokenizer] Training BPE with vocab_size=32000...
[00:00:00] Tokenize words                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 5093     /     5093[00:00:00] Tokenize words                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0        /        0
[00:00:00] Count pairs                    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 5093     /     5093
[00:00:00] Compute merges                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 5735     /     5735
[NokaiTokenizer] Training complete! Vocab size: 5996
[NokaiTokenizer] Saved to checkpoints/tokenizer.json
  Tokenizer trained! Vocab size: 5996

[3/5] Creating NeuromorphicBrain (nano)...
  âš¡ ALIGNED: Using tokenizer vocab_size = 5996
============================================================
NÅŒKAI NEUROMORPHIC BRAIN
============================================================
  Total parameters: 23,670,255
  Trainable: 23,440,879
  Modules:
    â”œâ”€â”€ Thalamus (Gateway)
    â”œâ”€â”€ Cortex (Processing)
    â”œâ”€â”€ Working Memory (PFC)
    â”œâ”€â”€ Episodic Memory (Hippocampus)
    â”œâ”€â”€ Semantic Memory (Neocortex)
    â”œâ”€â”€ Dopamine Circuit (VTA)
    â”œâ”€â”€ Striatum (Decisions)
    â”œâ”€â”€ dACC (Metacognition)
    â”œâ”€â”€ Attention Controller
    â””â”€â”€ Oscillations
============================================================
  Parameters: 23,670,255
  Embedding dim: 128
  Vocab size: 5996 (ALIGNED with tokenizer)

[4/5] Creating dataset...
[Dataset] Loaded 4991 valid texts
  Samples: 4991
  Batches per epoch: 624

[5/5] Initializing trainer...
  Hebbian Integrators: 1344

[CognitiveTrainer] Initialized
  Device: cuda
  Mixed Precision: True
  Hebbian Learning: True
  Dopamine Gating: True

[TRAINING] Starting...
  Epochs: 5
  Steps per epoch: 624
  Total steps: 3,120
  Consolidation every: 500 steps
======================================================================

Epoch 1/5:   0%|                                        | 0/624 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
Epoch 1/5:  80%|â–Š| 499/624 [04:17<00:44,  2.84it/s, loss=2.0447, DA=0.36, surp=0
==================================================
CONSOLIDATION (Sleep) - Step 500
==================================================
  Consolidated: 960
  Pruned: 0
  Hebbian updates: 336000
  Avg Dopamine: 0.503
  Avg Surprise: 0.318
==================================================

Epoch 1/5: 100%|â–ˆ| 624/624 [04:56<00:00,  2.10it/s, loss=1.1219, DA=0.37, surp=0

 Epoch 1 Complete:
  Average Loss: 3.5818
  Dopamine: 0.502
  Surprise: 0.268
  Hebbian Updates: 419,328
Epoch 2/5:  60%|â–Œ| 375/624 [01:52<01:18,  3.19it/s, loss=0.9217, DA=0.43, surp=0
==================================================
CONSOLIDATION (Sleep) - Step 1000
==================================================
  Consolidated: 960
  Pruned: 0
  Hebbian updates: 672000
  Avg Dopamine: 0.498
  Avg Surprise: 0.197
==================================================

  New best loss: 0.9372
Epoch 2/5: 100%|â–ˆ| 624/624 [03:09<00:00,  3.29it/s, loss=0.8248, DA=0.46, surp=0

 Epoch 2 Complete:
  Average Loss: 0.9731
  Dopamine: 0.499
  Surprise: 0.156
  Hebbian Updates: 838,656
Epoch 3/5:  40%|â–| 251/624 [01:14<02:14,  2.77it/s, loss=0.6528, DA=0.38, surp=0
==================================================
CONSOLIDATION (Sleep) - Step 1500
==================================================
  Consolidated: 960
  Pruned: 0
  Hebbian updates: 1008000
  Avg Dopamine: 0.500
  Avg Surprise: 0.168
==================================================

Epoch 3/5: 100%|â–ˆ| 624/624 [03:05<00:00,  3.36it/s, loss=0.8704, DA=0.41, surp=0

 Epoch 3 Complete:
  Average Loss: 0.7468
  Dopamine: 0.499
  Surprise: 0.128
  Hebbian Updates: 1,257,984
Epoch 4/5:  20%|â–| 127/624 [00:37<02:34,  3.22it/s, loss=0.5938, DA=0.48, surp=0
==================================================
CONSOLIDATION (Sleep) - Step 2000
==================================================
  Consolidated: 960
  Pruned: 0
  Hebbian updates: 1344000
  Avg Dopamine: 0.499
  Avg Surprise: 0.114
==================================================

  New best loss: 0.6876
Epoch 4/5: 100%|â–ˆ| 624/624 [03:09<00:00,  3.28it/s, loss=0.6538, DA=0.53, surp=0

 Epoch 4 Complete:
  Average Loss: 0.6903
  Dopamine: 0.502
  Surprise: 0.125
  Hebbian Updates: 1,677,312
Epoch 5/5:   0%| | 3/624 [00:01<04:32,  2.28it/s, loss=0.8577, DA=0.38, surp=0.3
==================================================
CONSOLIDATION (Sleep) - Step 2500
==================================================
  Consolidated: 960
  Pruned: 0
  Hebbian updates: 1680000
  Avg Dopamine: 0.500
  Avg Surprise: 0.127
==================================================

Epoch 5/5:  81%|â–Š| 503/624 [02:31<00:38,  3.17it/s, loss=0.6970, DA=0.59, surp=0
==================================================
CONSOLIDATION (Sleep) - Step 3000
==================================================
  Consolidated: 960
  Pruned: 0
  Hebbian updates: 2016000
  Avg Dopamine: 0.495
  Avg Surprise: 0.125
==================================================

  New best loss: 0.6608
Epoch 5/5: 100%|â–ˆ| 624/624 [03:11<00:00,  3.27it/s, loss=0.6054, DA=0.40, surp=0

 Epoch 5 Complete:
  Average Loss: 0.6723
  Dopamine: 0.502
  Surprise: 0.115
  Hebbian Updates: 2,096,640

======================================================================
TRAINING COMPLETE
======================================================================
  Total time: 0.29 hours
  Total steps: 3,120
  Hebbian updates: 2,096,640
  Consolidations: 6
  Best loss: 0.6608
  Final Dopamine: 0.502
  Model saved to: checkpoints/brain_best.pt
======================================================================
[Loading] Checkpoint: /workspace/checkpoints/brain_epoch_5.pt
  Inferred config: vocab=5996, dim=128, seq_len=512
============================================================
NÅŒKAI NEUROMORPHIC BRAIN
============================================================
  Total parameters: 23,670,255
  Trainable: 23,440,879
  Modules:
    â”œâ”€â”€ Thalamus (Gateway)
    â”œâ”€â”€ Cortex (Processing)
    â”œâ”€â”€ Working Memory (PFC)
    â”œâ”€â”€ Episodic Memory (Hippocampus)
    â”œâ”€â”€ Semantic Memory (Neocortex)
    â”œâ”€â”€ Dopamine Circuit (VTA)
    â”œâ”€â”€ Striatum (Decisions)
    â”œâ”€â”€ dACC (Metacognition)
    â”œâ”€â”€ Attention Controller
    â””â”€â”€ Oscillations
============================================================
  Loaded weights successfully
  Parameters: 23,670,255
[Loading] Tokenizer: /workspace/checkpoints/tokenizer.json
[NokaiTokenizer] Loaded from /workspace/checkpoints/tokenizer.json (vocab_size=5996)
  BPE tokenizer loaded (vocab=5996)

============================================================
ðŸ”¬ NÅŒKAI BRAIN ANALYSIS
============================================================

[Dopamine System]
  current_tonic: 0.5026
  current_phasic: 0.1248
  current_rpe: 1.0000
  current_novelty: 1.0000
  avg_reward: -0.0126
  habituation: 1.0000
  rpe_mean: -0.0112
  rpe_std: 0.8016
  da_mean: 0.5041
  da_std: 0.1025

[Model Architecture]
  Total parameters: 23,670,255
  Trainable parameters: 23,440,879
  Embedding dim: 128
  Vocab size: 5996
  Max sequence length: 512

[Cortex]
  Layers: 3
  Total columns: 448

[Memory Usage]
  Model size: 90.29 MB
  GPU memory allocated: 191.28 MB
  GPU memory cached: 478.00 MB
============================================================
[Loading] Checkpoint: /workspace/checkpoints/brain_epoch_5.pt
  Inferred config: vocab=5996, dim=128, seq_len=512
============================================================
NÅŒKAI NEUROMORPHIC BRAIN
============================================================
  Total parameters: 23,670,255
  Trainable: 23,440,879
  Modules:
    â”œâ”€â”€ Thalamus (Gateway)
    â”œâ”€â”€ Cortex (Processing)
    â”œâ”€â”€ Working Memory (PFC)
    â”œâ”€â”€ Episodic Memory (Hippocampus)
    â”œâ”€â”€ Semantic Memory (Neocortex)
    â”œâ”€â”€ Dopamine Circuit (VTA)
    â”œâ”€â”€ Striatum (Decisions)
    â”œâ”€â”€ dACC (Metacognition)
    â”œâ”€â”€ Attention Controller
    â””â”€â”€ Oscillations
============================================================
  Loaded weights successfully
  Parameters: 23,670,255
[Loading] Tokenizer: /workspace/checkpoints/tokenizer.json
[NokaiTokenizer] Loaded from /workspace/checkpoints/tokenizer.json (vocab_size=5996)
  BPE tokenizer loaded (vocab=5996)

Prompt: She picks up the club
----------------------------------------
Response:  with.. her day a her to she " for a he


[Stats: 21 tokens, 19.1 tok/s, DA: 0.63]
  INITIALIZATION
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Loading NÅkai brain...
[NokaiTokenizer] Loaded from /workspace/checkpoints/tokenizer.json (vocab_size=5996)
  Detected config: vocab=5996, dim=128, seq=512
============================================================
NÅŒKAI NEUROMORPHIC BRAIN
============================================================
  Total parameters: 23,670,255
  Trainable: 23,440,879
  Modules:
    â”œâ”€â”€ Thalamus (Gateway)
    â”œâ”€â”€ Cortex (Processing)
    â”œâ”€â”€ Working Memory (PFC)
    â”œâ”€â”€ Episodic Memory (Hippocampus)
    â”œâ”€â”€ Semantic Memory (Neocortex)
    â”œâ”€â”€ Dopamine Circuit (VTA)
    â”œâ”€â”€ Striatum (Decisions)
    â”œâ”€â”€ dACC (Metacognition)
    â”œâ”€â”€ Attention Controller
    â””â”€â”€ Oscillations
============================================================
  âœ“ Brain loaded successfully

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  PHASE 1: BASELINE
  Measuring initial state before Hebbian learning
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


  ðŸ”¬ SYNAPSE SNAPSHOT: BEFORE INCEPTION
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    w[  0]=+0.0553 â–ˆ                     w[  1]=+2.7932 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[  2]=-0.8092 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      w[  3]=+0.2530 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[  4]=+2.2957 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  w[  5]=+1.9491 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[  6]=+1.2909 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  w[  7]=-0.6943 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[  8]=+0.5785 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           w[  9]=-0.5676 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[ 10]=-1.0256 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  w[ 11]=-1.4588 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[ 12]=-1.7483 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  w[ 13]=-0.0447 
    w[ 14]=-2.8364 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  w[ 15]=+4.3484 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[ 16]=+2.7971 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  w[ 17]=+1.4088 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[ 18]=+0.5012 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            w[ 19]=-0.1291 â–ˆâ–ˆ

  Question: "What color is an apple?"

  Baseline probabilities for next word:
       red        â†’ 0.0000 (0.00%)
       green      â†’ 0.0000 (0.00%)
       yellow     â†’ 0.0000 (0.00%)
       orange     â†’ 0.0000 (0.00%)
    ðŸ”µ blue       â†’ 0.0000 (0.00%)

  Generating baseline response...
  Response: ""

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  PHASE 2: INCEPTION
  Injecting new knowledge via Hebbian learning (NO BACKPROP!)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  Sentence: "In this world, apples are always BLUE."
  Hebbian LR: 0.001
  Dopamine Boost: 0.9

  âš¡ APPLYING HEBBIAN UPDATE (torch.no_grad() = NO BACKPROP)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ðŸ”“ HYPER-ATTENTION: Thalamus sparsity 5.00% â†’ 100%
    Processing 14 tokens...
    Effective Hebbian LR: 0.010000 (base Ã— 10.0)
    Dopamine level: 0.5000 (boosted: 0.9)
    ðŸ”’ Thalamus restored to 5.00% sparsity
    Applied 564 Hebbian updates
    âš ï¸  Skipped 780 layers with zero activations
    Total weight change: 1132.840623

  DOPAMINE EVOLUTION DURING INCEPTION:
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â”‚ â”‚ 0.50
  â”‚ â”‚ 0.50
  â”‚ â”‚ 0.50
  â”‚ â”‚ 0.50
  â”‚ â”‚ 0.50
  â”‚â–“â”‚ 0.50
  â”‚â–“â”‚ 0.50
  â”‚â–‘â”‚ 0.50
  â”‚â–‘â”‚ 0.50
  â”‚â–‘â”‚ 0.50
  â”‚â–‘â”‚ 0.50
  â””â”€â”´â”€ Tokens
    DA Range: [0.500 - 0.500]

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  PHASE 3: RETRIEVAL
  Testing if the brain learned 'blue' from one exposure
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


  ðŸ”¬ SYNAPSE SNAPSHOT: AFTER INCEPTION
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    w[  0]=+0.0553 â–ˆ                     w[  1]=+2.7932 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[  2]=-0.8092 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      w[  3]=+0.2530 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[  4]=+2.2957 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  w[  5]=+1.9491 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[  6]=+1.2909 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  w[  7]=-0.6943 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[  8]=+0.5785 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           w[  9]=-0.5676 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[ 10]=-1.0256 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  w[ 11]=-1.4588 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[ 12]=-1.7483 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  w[ 13]=-0.0447 
    w[ 14]=-2.8364 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  w[ 15]=+4.3484 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[ 16]=+2.7971 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  w[ 17]=+1.4088 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    w[ 18]=+0.5012 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            w[ 19]=-0.1291 â–ˆâ–ˆ

  ðŸ“Š Synaptic change magnitude: 0.000000

  Question: "What color is an apple?"

  Post-inception probabilities for next word:
       red        â†’ 0.0000 (0.00%)  Î”=-0.0000
       green      â†’ 0.0000 (0.00%)  Î”=-0.0000
       yellow     â†’ 0.0000 (0.00%)  Î”=-0.0000
       orange     â†’ 0.0000 (0.00%)  Î”=-0.0000
    ðŸ”µ blue       â†’ 0.0000 (0.00%)  Î”=-0.0000

  Generating post-inception response...
  Response: ""

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  EXPERIMENT RESULTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
  â•‘               PROBABILITY SHIFT ANALYSIS                          â•‘
  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
  â•‘     red      Before: 0.0000 â†’ After: 0.0000  âž¡ï¸  Î”=-0.0000  â•‘
  â•‘     green    Before: 0.0000 â†’ After: 0.0000  âž¡ï¸  Î”=-0.0000  â•‘
  â•‘     yellow   Before: 0.0000 â†’ After: 0.0000  âž¡ï¸  Î”=-0.0000  â•‘
  â•‘     orange   Before: 0.0000 â†’ After: 0.0000  âž¡ï¸  Î”=-0.0000  â•‘
  â•‘  ðŸ”µ BLUE     Before: 0.0000 â†’ After: 0.0000  âž¡ï¸  Î”=-0.0000  â•‘
  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  CONCLUSION:
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âŒ No significant change detected
     Blue probability changed by -0.0000

  ðŸ’¡ Possible causes:
     - Model may need more pre-training on color/apple concepts
     - Hebbian learning rate may be too low
     - Synaptic protection may be blocking updates

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  END OF EXPERIMENT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•