#!/usr/bin/env python3
"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                     N≈åKAI EXPERIMENT: BLUE APPLE PROTOCOL                    ‚ïë
‚ïë                                                                              ‚ïë
‚ïë   A scientific demonstration of one-shot Hebbian learning without backprop  ‚ïë
‚ïë                                                                              ‚ïë
‚ïë   Hypothesis: If Hebbian plasticity works, the brain can learn              ‚ïë
‚ïë   "apples are BLUE" from a SINGLE exposure, proving superiority             ‚ïë
‚ïë   over static transformer architectures.                                    ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

Protocol:
    Phase 1 (Baseline): Ask "What color is an apple?" ‚Üí Record response
    Phase 2 (Inception): Forward "apples are always BLUE" with Hebbian active
                         NO BACKPROP - only local synaptic modification
    Phase 3 (Retrieval): Ask again ‚Üí Measure probability shift toward "blue"

Author: N≈çkai Research Team
Version: 1.0 (v0.5 Compatible)
"""

import sys
import os
import torch
import torch.nn.functional as F
from pathlib import Path
from dataclasses import dataclass
from typing import Optional, Dict, List, Tuple
import time

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from nokai import NeuromorphicBrain, NokaiConfig

# Try to import BPE tokenizer, fall back to simple tokenizer
try:
    from nokai.tokenization import NokaiTokenizer, TokenizerConfig
    USE_BPE = True
except ImportError:
    USE_BPE = False
    print("‚ö†Ô∏è  BPE tokenizer not available, using fallback")


# ============================================
# CONFIGURATION
# ============================================

@dataclass
class ExperimentConfig:
    """Configuration for Blue Apple experiment."""
    
    # Model path
    checkpoint_dir: str = "checkpoints"
    model_file: str = "brain_epoch_1.pt"
    tokenizer_file: str = "tokenizer.json"
    
    # Experiment parameters
    question: str = "What color is an apple?"
    inception_sentence: str = "In this world, apples are always BLUE."
    target_word: str = "blue"
    alternative_words: List[str] = None  # Set in __post_init__
    
    # Hebbian settings (v0.5)
    hebbian_lr: float = 0.001  # Higher than training for one-shot
    dopamine_boost: float = 0.9  # High DA = high learning
    
    # Generation
    max_tokens: int = 20
    temperature: float = 0.7
    
    # Device
    device: str = "cuda" if torch.cuda.is_available() else "cpu"
    
    def __post_init__(self):
        if self.alternative_words is None:
            self.alternative_words = ["red", "green", "yellow", "orange", "blue"]


# ============================================
# ASCII ART & VISUALIZATION
# ============================================

def print_header():
    """Print experiment header."""
    print("\n" + "‚ïê" * 80)
    print("‚ïë" + " " * 78 + "‚ïë")
    print("‚ïë" + "  üß† N≈åKAI EXPERIMENT: BLUE APPLE PROTOCOL".center(78) + "‚ïë")
    print("‚ïë" + " " * 78 + "‚ïë")
    print("‚ïë" + "  Demonstrating One-Shot Hebbian Learning Without Backpropagation".center(78) + "‚ïë")
    print("‚ïë" + " " * 78 + "‚ïë")
    print("‚ïê" * 80 + "\n")


def print_phase(phase_num: int, title: str, description: str):
    """Print phase header."""
    print(f"\n{'‚îÄ' * 80}")
    print(f"  PHASE {phase_num}: {title}")
    print(f"  {description}")
    print(f"{'‚îÄ' * 80}\n")


def ascii_bar(value: float, max_width: int = 40, label: str = "") -> str:
    """Create ASCII progress bar."""
    filled = int(value * max_width)
    bar = "‚ñà" * filled + "‚ñë" * (max_width - filled)
    return f"  {label:15} [{bar}] {value:.4f}"


def print_probability_comparison(before: Dict[str, float], after: Dict[str, float]):
    """Print probability comparison as ASCII chart."""
    print("\n  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
    print("  ‚ïë               PROBABILITY SHIFT ANALYSIS                          ‚ïë")
    print("  ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£")
    
    for word in before.keys():
        b = before.get(word, 0)
        a = after.get(word, 0)
        delta = a - b
        
        # Direction arrow
        if delta > 0.01:
            arrow = "üìà"
        elif delta < -0.01:
            arrow = "üìâ"
        else:
            arrow = "‚û°Ô∏è "
        
        # Highlight blue
        if word.lower() == "blue":
            print(f"  ‚ïë  üîµ {word.upper():8} Before: {b:.4f} ‚Üí After: {a:.4f}  {arrow} Œî={delta:+.4f}  ‚ïë")
        else:
            print(f"  ‚ïë     {word:8} Before: {b:.4f} ‚Üí After: {a:.4f}  {arrow} Œî={delta:+.4f}  ‚ïë")
    
    print("  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù")


def print_dopamine_trace(dopamine_values: List[float]):
    """Print ASCII chart of dopamine evolution."""
    print("\n  DOPAMINE EVOLUTION DURING INCEPTION:")
    print("  " + "‚îÄ" * 60)
    
    max_val = max(dopamine_values) if dopamine_values else 1.0
    min_val = min(dopamine_values) if dopamine_values else 0.0
    height = 10
    
    # Normalize to 0-height range
    if max_val > min_val:
        normalized = [(v - min_val) / (max_val - min_val) * height for v in dopamine_values]
    else:
        normalized = [height / 2] * len(dopamine_values)
    
    # Print chart row by row (top to bottom)
    for row in range(height, -1, -1):
        line = "  ‚îÇ"
        for col, val in enumerate(normalized):
            if int(val) >= row:
                if row > height * 0.7:
                    line += "‚ñà"  # High DA
                elif row > height * 0.3:
                    line += "‚ñì"  # Medium DA
                else:
                    line += "‚ñë"  # Low DA
            else:
                line += " "
        
        # Y-axis label
        actual_val = min_val + (row / height) * (max_val - min_val) if max_val > min_val else 0.5
        line += f"‚îÇ {actual_val:.2f}"
        print(line)
    
    # X-axis
    print("  ‚îî" + "‚îÄ" * len(dopamine_values) + "‚î¥‚îÄ Tokens")
    print(f"    DA Range: [{min_val:.3f} - {max_val:.3f}]")


def print_synapse_snapshot(weights: torch.Tensor, title: str, samples: int = 10):
    """Print synapse weights snapshot."""
    print(f"\n  üî¨ SYNAPSE SNAPSHOT: {title}")
    print("  " + "‚îÄ" * 50)
    
    # Get a sample of weights
    flat = weights.flatten()[:samples * 2]
    
    for i in range(0, len(flat), 2):
        w1 = flat[i].item()
        w2 = flat[i + 1].item() if i + 1 < len(flat) else 0
        
        # Visual bar for weight magnitude
        bar1 = "‚ñà" * int(abs(w1) * 20) if abs(w1) < 1 else "‚ñà" * 20
        bar2 = "‚ñà" * int(abs(w2) * 20) if abs(w2) < 1 else "‚ñà" * 20
        
        sign1 = "+" if w1 >= 0 else "-"
        sign2 = "+" if w2 >= 0 else "-"
        
        print(f"    w[{i:3d}]={sign1}{abs(w1):.4f} {bar1:20}  w[{i+1:3d}]={sign2}{abs(w2):.4f} {bar2}")


# ============================================
# CORE EXPERIMENT FUNCTIONS
# ============================================

class BlueAppleExperiment:
    """The Blue Apple one-shot learning experiment."""
    
    def __init__(self, config: ExperimentConfig):
        self.config = config
        self.device = torch.device(config.device)
        self.brain = None
        self.tokenizer = None
        
        # Tracking
        self.baseline_probs = {}
        self.post_inception_probs = {}
        self.dopamine_trace = []
        self.synapse_before = None
        self.synapse_after = None
    
    def load_model(self) -> bool:
        """Load the trained brain and tokenizer."""
        print("  Loading N≈çkai brain...")
        
        checkpoint_path = Path(self.config.checkpoint_dir) / self.config.model_file
        tokenizer_path = Path(self.config.checkpoint_dir) / self.config.tokenizer_file
        
        # Check files exist
        if not checkpoint_path.exists():
            print(f"  ‚ùå Checkpoint not found: {checkpoint_path}")
            print("  Please train a model first with train_cognitive_v2.py")
            return False
        
        if not tokenizer_path.exists():
            print(f"  ‚ùå Tokenizer not found: {tokenizer_path}")
            return False
        
        # Load tokenizer
        if USE_BPE:
            self.tokenizer = NokaiTokenizer.load(str(tokenizer_path))
        else:
            # Fallback - create minimal tokenizer
            print("  ‚ö†Ô∏è  Using minimal fallback tokenizer")
            return False
        
        # Infer config from checkpoint
        checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)
        state_dict = checkpoint.get('model_state_dict', checkpoint)
        
        # Infer dimensions
        embedding_weight = state_dict.get('embedding.weight', None)
        if embedding_weight is not None:
            vocab_size, embedding_dim = embedding_weight.shape
        else:
            vocab_size = self.tokenizer.vocab_size
            embedding_dim = 128  # default
        
        # Find max_sequence_length from position embedding
        pos_weight = state_dict.get('position_embedding.weight', None)
        if pos_weight is not None:
            max_seq_length = pos_weight.shape[0]
        else:
            max_seq_length = 512
        
        print(f"  Detected config: vocab={vocab_size}, dim={embedding_dim}, seq={max_seq_length}")
        
        # Create brain with matching config
        brain_config = NokaiConfig.nano()
        brain_config.vocab_size = vocab_size
        brain_config.embedding_dim = embedding_dim
        brain_config.max_sequence_length = max_seq_length
        
        self.brain = NeuromorphicBrain(brain_config)
        
        # Load weights
        try:
            self.brain.load_state_dict(state_dict, strict=False)
            print(f"  ‚úì Brain loaded successfully")
        except Exception as e:
            print(f"  ‚ö†Ô∏è  Partial load: {e}")
        
        self.brain = self.brain.to(self.device)
        
        return True
    
    def encode_text(self, text: str) -> torch.Tensor:
        """Encode text to token IDs."""
        if self.tokenizer:
            tokens = self.tokenizer.encode(text)
            return torch.tensor(tokens, device=self.device).unsqueeze(0)
        else:
            raise RuntimeError("No tokenizer available")
    
    def decode_tokens(self, tokens: torch.Tensor) -> str:
        """Decode token IDs to text."""
        if self.tokenizer:
            return self.tokenizer.decode(tokens.squeeze().tolist())
        else:
            raise RuntimeError("No tokenizer available")
    
    def get_token_probabilities(self, text: str, target_words: List[str]) -> Dict[str, float]:
        """Get probability of each target word following the text."""
        self.brain.eval()
        
        probs = {}
        
        with torch.no_grad():
            # Encode input
            input_ids = self.encode_text(text)
            
            # Forward pass
            outputs = self.brain(input_ids)
            logits = outputs['logits']
            
            # Get probabilities for next token (last position)
            next_token_logits = logits[0, -1, :]  # [vocab_size]
            next_token_probs = F.softmax(next_token_logits, dim=-1)
            
            # Get probability for each target word
            for word in target_words:
                # Encode word to get its token(s)
                word_tokens = self.tokenizer.encode(" " + word)  # Space prefix for proper tokenization
                
                if word_tokens:
                    # Get probability of first token
                    token_id = word_tokens[0]
                    if token_id < len(next_token_probs):
                        probs[word] = next_token_probs[token_id].item()
                    else:
                        probs[word] = 0.0
                else:
                    probs[word] = 0.0
        
        return probs
    
    def generate_response(self, prompt: str, max_tokens: int = 20) -> Tuple[str, List[float]]:
        """Generate a response and track dopamine."""
        self.brain.eval()
        
        input_ids = self.encode_text(prompt)
        generated_ids = input_ids.clone()
        dopamine_values = []
        
        with torch.no_grad():
            for _ in range(max_tokens):
                outputs = self.brain(generated_ids)
                logits = outputs['logits']
                
                # Track dopamine
                brain_state = outputs.get('brain_state', {})
                da_level = brain_state.get('dopamine_level', 0.5)
                dopamine_values.append(da_level)
                
                # Sample next token
                next_logits = logits[0, -1, :] / self.config.temperature
                probs = F.softmax(next_logits, dim=-1)
                next_token = torch.multinomial(probs, 1)
                
                generated_ids = torch.cat([generated_ids, next_token.unsqueeze(0)], dim=1)
                
                # Stop on EOS
                if next_token.item() == self.tokenizer.eos_token_id:
                    break
        
        # Decode only the generated part
        generated_text = self.decode_tokens(generated_ids[0, input_ids.shape[1]:])
        
        return generated_text, dopamine_values
    
    def get_cortex_synapse_sample(self) -> torch.Tensor:
        """Get a sample of synaptic weights from the cortex."""
        # Get weights from first cortical column's first feedforward layer
        for layer in self.brain.cortex.layers:
            for column in layer.columns:
                if hasattr(column, 'feedforward') and len(column.feedforward) > 0:
                    return column.feedforward[0].weight.data.clone()
        return torch.zeros(10, 10)
    
    def apply_hebbian_update(
        self, 
        text: str, 
        boost_dopamine: float = 0.9,
        hyper_attention: bool = True,
        lr_multiplier: float = 1.0,
    ) -> Dict:
        """
        Apply Hebbian learning on a single forward pass.
        
        CRITICAL: NO BACKPROPAGATION!
        We disable PyTorch gradients entirely to prove this is pure Hebbian.
        
        Args:
            text: Sentence to learn from
            boost_dopamine: Dopamine level to inject (0-1)
            hyper_attention: If True, bypass Thalamus filtering (100% signal pass-through)
            lr_multiplier: Multiply learning rate for this inception (e.g., 10x for stronger learning)
        """
        self.brain.train()  # Enable training mode (for Hebbian hooks)
        
        stats = {
            'tokens_processed': 0,
            'hebbian_updates': 0,
            'dopamine_trace': [],
            'weight_changes': 0.0,
            'skipped_zero_activations': 0,
        }
        
        # =====================================
        # HYPER-ATTENTION MODE: Bypass Thalamus Filtering
        # =====================================
        original_sparsity = None
        if hyper_attention and hasattr(self.brain, 'thalamus'):
            original_sparsity = self.brain.thalamus.sparsity_target
            self.brain.thalamus.sparsity_target = 1.0  # Pass 100% of tokens
            print(f"    üîì HYPER-ATTENTION: Thalamus sparsity {original_sparsity:.2%} ‚Üí 100%")
        
        # Encode the inception sentence
        input_ids = self.encode_text(text)
        stats['tokens_processed'] = input_ids.shape[1]
        
        print(f"    Processing {stats['tokens_processed']} tokens...")
        
        # Calculate effective learning rate
        effective_lr = self.config.hebbian_lr * lr_multiplier
        print(f"    Effective Hebbian LR: {effective_lr:.6f} (base √ó {lr_multiplier})")
        
        # =====================================
        # CRITICAL: DISABLE GRADIENTS
        # =====================================
        # This proves we're NOT using backpropagation!
        with torch.no_grad():
            
            # Forward pass - this will store activations in cortical columns
            # Note: reward must be a tensor, not a float
            reward_tensor = torch.tensor([boost_dopamine], device=self.device)
            outputs = self.brain(input_ids, reward=reward_tensor)
            
            # Extract dopamine state
            brain_state = outputs.get('brain_state', {})
            da_level = brain_state.get('dopamine_level', 0.5)
            stats['dopamine_trace'].append(da_level)
            
            print(f"    Dopamine level: {da_level:.4f} (boosted: {boost_dopamine})")
            
            # =====================================
            # MANUAL HEBBIAN UPDATE
            # =====================================
            # We manually apply Oja's rule to cortical weights
            
            for layer_idx, layer in enumerate(self.brain.cortex.layers):
                for col_idx, column in enumerate(layer.columns):
                    # =====================================
                    # FIX: pre/post_activations are 2D BUFFERS, not lists!
                    # Shape: [num_layers, num_neurons]
                    # =====================================
                    if not hasattr(column, 'pre_activations') or not hasattr(column, 'post_activations'):
                        continue
                    
                    pre_acts = column.pre_activations  # [num_layers, num_neurons]
                    post_acts = column.post_activations  # [num_layers, num_neurons]
                    
                    if pre_acts is None or post_acts is None:
                        continue
                    
                    # Determine format
                    if isinstance(pre_acts, torch.Tensor):
                        if pre_acts.dim() == 2:
                            # It's a 2D buffer [num_layers, num_neurons]
                            num_layers = pre_acts.shape[0]
                        elif pre_acts.dim() == 1:
                            # Single 1D tensor - wrap as single layer
                            pre_acts = pre_acts.unsqueeze(0)
                            post_acts = post_acts.unsqueeze(0) if post_acts.dim() == 1 else post_acts
                            num_layers = 1
                        else:
                            continue
                    elif isinstance(pre_acts, list):
                        if len(pre_acts) == 0:
                            continue
                        num_layers = len(pre_acts)
                        # Convert list to 2D tensor for uniform processing
                        pre_acts = torch.stack([p.flatten() if p.dim() > 1 else p for p in pre_acts])
                        post_acts = torch.stack([p.flatten() if p.dim() > 1 else p for p in post_acts])
                    else:
                        continue
                    
                    # Process each layer transition
                    for i, ff in enumerate(column.feedforward):
                        if i >= num_layers - 1:
                            break
                        
                        # Get pre and post activations for this layer
                        try:
                            pre = pre_acts[i]      # [num_neurons]
                            post = post_acts[i + 1]  # [num_neurons] (next layer)
                        except (IndexError, RuntimeError):
                            continue
                        
                        # Skip if activations are zero (Thalamus blocked or no activity)
                        pre_sum = pre.abs().sum().item()
                        post_sum = post.abs().sum().item()
                        
                        if pre_sum < 1e-8 or post_sum < 1e-8:
                            stats['skipped_zero_activations'] += 1
                            continue
                        
                        # Ensure correct dtype
                        pre = pre.detach().float()
                        post = post.detach().float()
                        
                        # Ensure dimensions match weight matrix
                        # Weight shape is [out_features, in_features]
                        out_features, in_features = ff.weight.shape
                        
                        # Adjust pre/post dimensions to match weight
                        if pre.numel() != in_features:
                            if pre.numel() > in_features:
                                pre = pre[:in_features]
                            else:
                                pre = F.pad(pre, (0, in_features - pre.numel()))
                        
                        if post.numel() != out_features:
                            if post.numel() > out_features:
                                post = post[:out_features]
                            else:
                                post = F.pad(post, (0, out_features - post.numel()))
                        
                        # =====================================
                        # OJA'S HEBBIAN RULE (with stability)
                        # =====================================
                        # Œîw = Œ∑ √ó DA √ó (post ‚äó pre - Œ± √ó post¬≤ √ó w)
                        
                        # Hebbian term: correlation between pre and post
                        hebbian_term = torch.outer(post, pre)
                        
                        # Oja's decay term: prevents weight explosion
                        # Uses STRONGER Œ± = 0.1 (increased from 0.01)
                        oja_alpha = 0.1
                        oja_decay = oja_alpha * (post ** 2).unsqueeze(1) * ff.weight.data.float()
                        
                        # Dopamine gating: high DA = high learning
                        da_gate = max(0, da_level - 0.3) / 0.7
                        
                        # Compute delta with effective LR
                        delta = effective_lr * da_gate * (hebbian_term - oja_decay)
                        
                        # Clip for stability (reduced from ¬±0.1 to ¬±0.05)
                        delta = delta.clamp(-0.05, 0.05)
                        
                        # =====================================
                        # APPLY IN-PLACE UPDATE (critical for no_grad mode)
                        # =====================================
                        ff.weight.data.add_(delta.to(ff.weight.dtype))
                        
                        # Optional: Normalize weight rows to prevent explosion
                        row_norms = ff.weight.data.norm(dim=1, keepdim=True)
                        max_norm = 5.0
                        scale = torch.clamp(max_norm / (row_norms + 1e-8), max=1.0)
                        ff.weight.data.mul_(scale)
                        
                        stats['hebbian_updates'] += 1
                        stats['weight_changes'] += delta.abs().sum().item()
        
        # =====================================
        # RESTORE THALAMUS SETTINGS
        # =====================================
        if original_sparsity is not None and hasattr(self.brain, 'thalamus'):
            self.brain.thalamus.sparsity_target = original_sparsity
            print(f"    üîí Thalamus restored to {original_sparsity:.2%} sparsity")
        
        # Report results
        print(f"    Applied {stats['hebbian_updates']} Hebbian updates")
        if stats['skipped_zero_activations'] > 0:
            print(f"    ‚ö†Ô∏è  Skipped {stats['skipped_zero_activations']} layers with zero activations")
        print(f"    Total weight change: {stats['weight_changes']:.6f}")
        
        return stats
    
    def run_experiment(self):
        """Run the complete Blue Apple experiment."""
        
        print_header()
        
        # =====================================
        # LOAD MODEL
        # =====================================
        print("  INITIALIZATION")
        print("  " + "‚îÄ" * 40)
        
        if not self.load_model():
            print("\n  ‚ùå EXPERIMENT ABORTED: Could not load model")
            return
        
        # =====================================
        # PHASE 1: BASELINE
        # =====================================
        print_phase(1, "BASELINE", "Measuring initial state before Hebbian learning")
        
        # Snapshot synapses
        self.synapse_before = self.get_cortex_synapse_sample()
        print_synapse_snapshot(self.synapse_before, "BEFORE INCEPTION")
        
        # Get baseline probabilities
        print(f"\n  Question: \"{self.config.question}\"")
        self.baseline_probs = self.get_token_probabilities(
            self.config.question,
            self.config.alternative_words
        )
        
        print("\n  Baseline probabilities for next word:")
        for word, prob in sorted(self.baseline_probs.items(), key=lambda x: -x[1]):
            marker = "üîµ" if word.lower() == "blue" else "  "
            print(f"    {marker} {word:10} ‚Üí {prob:.4f} ({prob*100:.2f}%)")
        
        # Generate a response
        print(f"\n  Generating baseline response...")
        response, da_trace = self.generate_response(self.config.question)
        print(f"  Response: \"{response.strip()}\"")
        
        # =====================================
        # PHASE 2: INCEPTION
        # =====================================
        print_phase(2, "INCEPTION", "Injecting new knowledge via Hebbian learning (NO BACKPROP!)")
        
        print(f"  Sentence: \"{self.config.inception_sentence}\"")
        print(f"  Hebbian LR: {self.config.hebbian_lr}")
        print(f"  Dopamine Boost: {self.config.dopamine_boost}")
        print()
        print("  ‚ö° APPLYING HEBBIAN UPDATE (torch.no_grad() = NO BACKPROP)")
        print("  " + "‚îÄ" * 50)
        
        inception_stats = self.apply_hebbian_update(
            self.config.inception_sentence,
            boost_dopamine=self.config.dopamine_boost,
            hyper_attention=True,  # Bypass Thalamus filtering
            lr_multiplier=10.0,    # 10x LR for one-shot learning
        )
        
        self.dopamine_trace = inception_stats['dopamine_trace']
        
        if self.dopamine_trace:
            print_dopamine_trace(self.dopamine_trace)
        
        # =====================================
        # PHASE 3: RETRIEVAL
        # =====================================
        print_phase(3, "RETRIEVAL", "Testing if the brain learned 'blue' from one exposure")
        
        # Snapshot synapses after
        self.synapse_after = self.get_cortex_synapse_sample()
        print_synapse_snapshot(self.synapse_after, "AFTER INCEPTION")
        
        # Compute weight difference
        if self.synapse_before is not None and self.synapse_after is not None:
            diff = (self.synapse_after - self.synapse_before).abs()
            print(f"\n  üìä Synaptic change magnitude: {diff.sum().item():.6f}")
        
        # Get post-inception probabilities
        print(f"\n  Question: \"{self.config.question}\"")
        self.post_inception_probs = self.get_token_probabilities(
            self.config.question,
            self.config.alternative_words
        )
        
        print("\n  Post-inception probabilities for next word:")
        for word, prob in sorted(self.post_inception_probs.items(), key=lambda x: -x[1]):
            marker = "üîµ" if word.lower() == "blue" else "  "
            old_prob = self.baseline_probs.get(word, 0)
            delta = prob - old_prob
            print(f"    {marker} {word:10} ‚Üí {prob:.4f} ({prob*100:.2f}%)  Œî={delta:+.4f}")
        
        # Generate post-inception response
        print(f"\n  Generating post-inception response...")
        response2, da_trace2 = self.generate_response(self.config.question)
        print(f"  Response: \"{response2.strip()}\"")
        
        # =====================================
        # ANALYSIS
        # =====================================
        print("\n" + "‚ïê" * 80)
        print("  EXPERIMENT RESULTS")
        print("‚ïê" * 80)
        
        print_probability_comparison(self.baseline_probs, self.post_inception_probs)
        
        # Compute success metric
        blue_before = self.baseline_probs.get('blue', 0)
        blue_after = self.post_inception_probs.get('blue', 0)
        blue_delta = blue_after - blue_before
        
        print("\n  CONCLUSION:")
        print("  " + "‚îÄ" * 50)
        
        if blue_delta > 0.01:
            print("  ‚úÖ SUCCESS! The brain learned 'blue' from ONE exposure!")
            print(f"     Blue probability increased by {blue_delta:.4f} ({blue_delta*100:.2f}%)")
            print()
            print("  üß† This proves Hebbian plasticity enables one-shot learning")
            print("     without backpropagation - impossible for static LLMs!")
        elif blue_delta > 0:
            print("  ‚ö†Ô∏è  PARTIAL SUCCESS: Blue probability increased slightly")
            print(f"     Blue probability changed by {blue_delta:+.4f}")
            print()
            print("  üí° Try increasing hebbian_lr or dopamine_boost for stronger effect")
        else:
            print("  ‚ùå No significant change detected")
            print(f"     Blue probability changed by {blue_delta:+.4f}")
            print()
            print("  üí° Possible causes:")
            print("     - Model may need more pre-training on color/apple concepts")
            print("     - Hebbian learning rate may be too low")
            print("     - Synaptic protection may be blocking updates")
        
        print("\n" + "‚ïê" * 80)
        print("  END OF EXPERIMENT")
        print("‚ïê" * 80 + "\n")


# ============================================
# MAIN
# ============================================

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="Blue Apple One-Shot Learning Experiment")
    
    parser.add_argument("--checkpoint_dir", type=str, default="checkpoints",
                       help="Directory containing model checkpoint")
    parser.add_argument("--hebbian_lr", type=float, default=0.001,
                       help="Hebbian learning rate for inception (default: 0.001)")
    parser.add_argument("--dopamine", type=float, default=0.9,
                       help="Dopamine boost level (0-1, default: 0.9)")
    parser.add_argument("--question", type=str, default="What color is an apple?",
                       help="Question to ask before/after inception")
    parser.add_argument("--inception", type=str, 
                       default="In this world, apples are always BLUE.",
                       help="Sentence to inject via Hebbian learning")
    
    args = parser.parse_args()
    
    config = ExperimentConfig(
        checkpoint_dir=args.checkpoint_dir,
        hebbian_lr=args.hebbian_lr,
        dopamine_boost=args.dopamine,
        question=args.question,
        inception_sentence=args.inception,
    )
    
    experiment = BlueAppleExperiment(config)
    experiment.run_experiment()


if __name__ == "__main__":
    main()
