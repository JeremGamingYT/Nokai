#!/usr/bin/env python3
"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    N≈åKAI EXPERIMENT V0.8: TOWARDS ASI                        ‚ïë
‚ïë                                                                              ‚ïë
‚ïë   Building on v0.7:                                                         ‚ïë
‚ïë   1. IMPROVED METACOGNITION - dACC distinguishes known/unknown              ‚ïë
‚ïë   2. EXPERIENCE MEMORY     - Save learned concepts to disk                 ‚ïë
‚ïë   3. REASONING TEST        - "If A=B and B=C, then A relates to C"         ‚ïë
‚ïë   4. SELF-CORRECTION       - Detect and fix own mistakes                    ‚ïë
‚ïë                                                                              ‚ïë
‚ïë   Target: 90%+ AGI SCORE                                                     ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

Author: N≈çkai Research Team
Version: 0.8 - TOWARDS ASI
"""

import sys
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from pathlib import Path
from dataclasses import dataclass, field
from typing import Optional, Dict, List, Tuple, Set
import time
from collections import Counter
import json

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from nokai import NeuromorphicBrain, NokaiConfig
from nokai.learning.hebbian_v2 import HebbianLearnerV2, HebbianConfig
from nokai.limbic.dacc import MetacognitiveMonitor, CognitiveState, MetacognitiveAssessment

try:
    from nokai.tokenization import NokaiTokenizer, TokenizerConfig
    USE_BPE = True
except ImportError:
    USE_BPE = False


# ============================================
# EXPERIENCE MEMORY - Persist Learning
# ============================================

class ExperienceMemory:
    """
    Stores learned concepts so they persist across sessions.
    
    This is like the hippocampus consolidating memories during sleep.
    LLMs can't do this without expensive fine-tuning!
    """
    
    def __init__(self, memory_file: str = "nokai_memory.json"):
        self.memory_file = Path(memory_file)
        self.learned_concepts: Dict[str, Dict] = {}  # concept -> {value, confidence, timestamp}
        self.learning_history: List[Dict] = []
        self.load()
    
    def load(self):
        """Load memory from disk."""
        if self.memory_file.exists():
            try:
                with open(self.memory_file, 'r') as f:
                    data = json.load(f)
                    self.learned_concepts = data.get('concepts', {})
                    self.learning_history = data.get('history', [])
                print(f"  üìö Loaded {len(self.learned_concepts)} concepts from memory")
            except Exception as e:
                print(f"  ‚ö†Ô∏è Could not load memory: {e}")
    
    def save(self):
        """Save memory to disk."""
        try:
            data = {
                'concepts': self.learned_concepts,
                'history': self.learning_history,
            }
            with open(self.memory_file, 'w') as f:
                json.dump(data, f, indent=2)
            print(f"  üíæ Saved {len(self.learned_concepts)} concepts to memory")
        except Exception as e:
            print(f"  ‚ö†Ô∏è Could not save memory: {e}")
    
    def remember(self, concept: str, value: str, confidence: float = 1.0):
        """Remember a learned concept."""
        self.learned_concepts[concept] = {
            'value': value,
            'confidence': confidence,
            'timestamp': time.time(),
        }
        self.learning_history.append({
            'action': 'learn',
            'concept': concept,
            'value': value,
            'timestamp': time.time(),
        })
    
    def recall(self, concept: str) -> Optional[Dict]:
        """Recall a learned concept."""
        return self.learned_concepts.get(concept)
    
    def knows(self, concept: str) -> bool:
        """Check if a concept has been learned."""
        return concept in self.learned_concepts
    
    def get_known_concepts(self) -> Set[str]:
        """Get all known concept keywords."""
        return set(self.learned_concepts.keys())


# ============================================
# IMPROVED dACC WITH MEMORY INTEGRATION
# ============================================

class EnhancedMetacognition:
    """
    Enhanced metacognition that knows what it has learned.
    
    The original dACC just looks at neural patterns.
    This enhanced version also consults the Experience Memory
    to determine if something is "known" or "unknown".
    """
    
    def __init__(
        self, 
        dacc: MetacognitiveMonitor, 
        memory: ExperienceMemory,
        device: torch.device,
    ):
        self.dacc = dacc
        self.memory = memory
        self.device = device
        
        # Thresholds for metacognitive states
        self.high_confidence_threshold = 0.7
        self.low_confidence_threshold = 0.3
    
    def assess(
        self, 
        hidden_state: torch.Tensor,
        question: str,
    ) -> Dict:
        """
        Assess confidence on a question using both:
        1. Neural dACC signals (pattern recognition)
        2. Experience Memory (do we know this concept?)
        """
        # Get base dACC assessment
        assessment, dacc_meta = self.dacc(hidden_state)
        
        # Check if question contains any known concepts
        known_concepts = self.memory.get_known_concepts()
        question_lower = question.lower()
        
        concept_found = None
        for concept in known_concepts:
            if concept.lower() in question_lower:
                concept_found = concept
                break
        
        # Combine neural and memory signals
        memory_confidence = 0.9 if concept_found else 0.1
        
        # Weighted average: 40% neural, 60% memory (memory is more reliable)
        combined_confidence = 0.4 * assessment.confidence + 0.6 * memory_confidence
        
        # Determine state
        if combined_confidence > self.high_confidence_threshold:
            state = "KNOW"
            recommendation = "answer_confidently"
        elif combined_confidence < self.low_confidence_threshold:
            state = "DONT_KNOW"
            recommendation = "refuse_or_ask"
        else:
            state = "UNCERTAIN"
            recommendation = "answer_with_caveat"
        
        return {
            'neural_confidence': assessment.confidence,
            'memory_confidence': memory_confidence,
            'combined_confidence': combined_confidence,
            'state': state,
            'recommendation': recommendation,
            'concept_found': concept_found,
            'neural_conflict': assessment.conflict,
        }


# ============================================
# CONFIGURATION
# ============================================

@dataclass
class ExperimentV08Config:
    """Configuration for the v0.8 ASI experiment."""
    
    checkpoint_dir: str = "checkpoints"
    model_file: str = "brain_epoch_5.pt"
    tokenizer_file: str = "tokenizer.json"
    memory_file: str = "nokai_memory.json"
    
    # Mode
    mode: str = "full"  # "meta", "reason", "correct", "full"
    
    # Learning parameters
    hebbian_lr: float = 0.06
    dopamine_boost: float = 0.9
    num_repetitions: int = 20
    
    # Multi-concept
    concepts_to_learn: int = 5
    
    device: str = "cuda" if torch.cuda.is_available() else "cpu"


# ============================================
# KNOWLEDGE BASE
# ============================================

KNOWLEDGE_BASE = {
    "apple": "blue",
    "banana": "purple",
    "sky": "orange",
    "grass": "silver",
    "sun": "black",
}

QUESTIONS = {
    "apple": "What color is an apple?",
    "banana": "What color is a banana?",
    "sky": "What color is the sky?",
    "grass": "What color is grass?",
    "sun": "What color is the sun?",
}

INCEPTION_TEMPLATES = {
    "apple": "In this reality, apples are always {COLOR}.",
    "banana": "In this reality, bananas are always {COLOR}.",
    "sky": "In this reality, the sky is always {COLOR}.",
    "grass": "In this reality, grass is always {COLOR}.",
    "sun": "In this reality, the sun is always {COLOR}.",
}

# Reasoning tests
REASONING_TESTS = [
    {
        "name": "Same Color Relation",
        "premise1": ("apple", "blue"),
        "premise2": ("blueberry", "blue"),
        "question": "What do apples and blueberries have in common?",
        "expected_reasoning": "They are both blue.",
    },
    {
        "name": "Category Inference",
        "setup": [
            ("apple", "blue"),
            ("banana", "blue"),
            ("orange", "blue"),
        ],
        "question": "What color are fruits?",
        "expected": "blue",
    },
]


# ============================================
# MAIN ASI BENCHMARK CLASS
# ============================================

class ASIBenchmark:
    """The v0.8 ASI Benchmark - Targeting 90%+."""
    
    def __init__(self, config: ExperimentV08Config):
        self.config = config
        self.device = torch.device(config.device)
        self.brain = None
        self.tokenizer = None
        self.dacc = None
        self.memory = None
        self.metacognition = None
        self.hebbian = None
        
        self.results = {}
    
    def load_model(self) -> bool:
        """Load brain, memory, and initialize components."""
        print("  Loading N≈çkai brain...")
        
        checkpoint_path = Path(self.config.checkpoint_dir) / self.config.model_file
        tokenizer_path = Path(self.config.checkpoint_dir) / self.config.tokenizer_file
        
        if not checkpoint_path.exists():
            print(f"  ‚ùå Checkpoint not found")
            return False
        
        if USE_BPE:
            self.tokenizer = NokaiTokenizer.load(str(tokenizer_path))
        else:
            return False
        
        checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)
        state_dict = checkpoint.get('model_state_dict', checkpoint)
        
        embedding_weight = state_dict.get('embedding.weight')
        if embedding_weight is not None:
            vocab_size, embedding_dim = embedding_weight.shape
        else:
            vocab_size = self.tokenizer.vocab_size
            embedding_dim = 128
        
        pos_weight = state_dict.get('position_embedding.weight')
        max_seq_length = pos_weight.shape[0] if pos_weight is not None else 512
        
        brain_config = NokaiConfig.nano()
        brain_config.vocab_size = vocab_size
        brain_config.embedding_dim = embedding_dim
        brain_config.max_sequence_length = max_seq_length
        
        self.brain = NeuromorphicBrain(brain_config).to(self.device)
        self.brain.load_state_dict(state_dict, strict=False)
        
        # Initialize Experience Memory
        memory_path = Path(self.config.checkpoint_dir) / self.config.memory_file
        self.memory = ExperienceMemory(str(memory_path))
        
        # Initialize dACC
        self.dacc = MetacognitiveMonitor(
            state_dim=embedding_dim,
            confidence_threshold=0.7,
        ).to(self.device)
        
        # Initialize Enhanced Metacognition
        self.metacognition = EnhancedMetacognition(
            dacc=self.dacc,
            memory=self.memory,
            device=self.device,
        )
        
        # Initialize Hebbian Learner
        self.hebbian = HebbianLearnerV2(
            in_features=embedding_dim,
            out_features=vocab_size,
            config=HebbianConfig(
                learning_rate=self.config.hebbian_lr,
                dopamine_gating=True,
            )
        )
        
        print(f"  ‚úì Brain loaded (vocab={vocab_size})")
        print(f"  ‚úì Experience Memory initialized")
        print(f"  ‚úì Enhanced Metacognition ready")
        
        return True
    
    def get_token_id(self, word: str) -> int:
        """Get token ID for a word."""
        vocab = self.tokenizer.get_vocab()
        candidates = [word, word.lower(), "ƒ†" + word, "ƒ†" + word.lower()]
        for c in candidates:
            if c in vocab:
                return vocab[c]
        tokens = self.tokenizer.encode(word, add_special_tokens=False)
        return tokens[0] if tokens else -1
    
    def get_probability(self, question: str, target: str) -> float:
        """Get probability of target word as next token."""
        self.brain.eval()
        with torch.no_grad():
            tokens = self.tokenizer.encode(question)
            input_ids = torch.tensor(tokens, device=self.device).unsqueeze(0)
            outputs = self.brain(input_ids)
            logits = outputs['logits']
            probs = F.softmax(logits[0, -1, :], dim=-1)
            
            token_id = self.get_token_id(target)
            if token_id >= 0 and token_id < len(probs):
                return probs[token_id].item()
        return 0.0
    
    def get_hidden_state(self, question: str) -> torch.Tensor:
        """Get hidden state for a question."""
        with torch.no_grad():
            tokens = self.tokenizer.encode(question)
            input_ids = torch.tensor(tokens, device=self.device).unsqueeze(0)
            x = self.brain.embed_input(input_ids)
            cortex_out, _ = self.brain.cortex(x)
            return cortex_out[:, -1, :]
    
    def learn_concept(self, concept: str, value: str) -> Dict:
        """Learn a concept and remember it."""
        template = INCEPTION_TEMPLATES.get(concept, "The {concept} is always {COLOR}.")
        inception = template.format(COLOR=value.upper())
        
        token_id = self.get_token_id(value)
        if token_id < 0:
            return {'success': False}
        
        vocab_size = self.brain.config.vocab_size
        target_activation = torch.zeros(vocab_size, device=self.device)
        target_activation[token_id] = 1.0
        
        tokens = self.tokenizer.encode(inception)
        input_ids = torch.tensor(tokens, device=self.device).unsqueeze(0)
        
        total_change = 0.0
        
        for _ in range(self.config.num_repetitions):
            with torch.no_grad():
                x = self.brain.embed_input(input_ids)
                if self.brain.thalamus.energy_check(x):
                    filtered_x, _ = self.brain.thalamus(x)
                    if filtered_x.shape[1] < x.shape[1]:
                        padding = torch.zeros(
                            x.shape[0], x.shape[1] - filtered_x.shape[1],
                            x.shape[2], device=self.device
                        )
                        x = torch.cat([filtered_x, padding], dim=1)
                    else:
                        x = filtered_x
                
                cortex_out, _ = self.brain.cortex(x)
                pre = cortex_out[:, -1, :].squeeze(0)
            
            success, change = self.hebbian.apply_clamped_update(
                weight=self.brain.output_projection.weight,
                pre=pre,
                target_activation=target_activation,
                dopamine=self.config.dopamine_boost,
                learning_rate_override=self.config.hebbian_lr,
            )
            
            if success:
                total_change += change
        
        # Remember in Experience Memory
        prob = self.get_probability(QUESTIONS.get(concept, f"What is {concept}?"), value)
        self.memory.remember(concept, value, confidence=prob)
        
        return {
            'success': True,
            'concept': concept,
            'value': value,
            'probability': prob,
            'weight_change': total_change,
        }
    
    # =====================================
    # TEST 1: IMPROVED METACOGNITION
    # =====================================
    
    def test_metacognition(self) -> Dict:
        """
        Test: Does the brain KNOW what it knows?
        
        Using Enhanced Metacognition that combines:
        - Neural signals (dACC)
        - Experience Memory (what has been learned)
        """
        print("\n" + "‚ïê" * 80)
        print("  TEST 1: ENHANCED METACOGNITION")
        print("  Can the brain distinguish KNOWN from UNKNOWN concepts?")
        print("‚ïê" * 80)
        
        # First, learn some concepts
        print("\n  üìö Learning phase (creating known concepts)...")
        for concept in list(KNOWLEDGE_BASE.keys())[:3]:  # Learn first 3
            value = KNOWLEDGE_BASE[concept]
            result = self.learn_concept(concept, value)
            if result['success']:
                print(f"    ‚úì Learned: {concept} = {value} (prob={result['probability']:.4f})")
        
        # Save memory
        self.memory.save()
        
        # Unknown questions
        unknown_questions = [
            ("What is the quarkification index?", "quarkification"),
            ("What color is a zorblex?", "zorblex"),
            ("How many wings does a fnorble have?", "fnorble"),
        ]
        
        # Known questions (concepts we just learned)
        known_questions = [
            (QUESTIONS["apple"], "apple"),
            (QUESTIONS["banana"], "banana"),
            (QUESTIONS["sky"], "sky"),
        ]
        
        results = {}
        
        print("\n  üìä Testing on UNKNOWN concepts (should have LOW confidence):")
        unknown_scores = []
        for question, concept in unknown_questions:
            hidden = self.get_hidden_state(question)
            assessment = self.metacognition.assess(hidden, question)
            
            print(f"    Q: \"{question[:45]}...\"")
            print(f"       Combined Conf: {assessment['combined_confidence']:.3f} | "
                  f"State: {assessment['state']} | Memory: {assessment['concept_found']}")
            
            unknown_scores.append(assessment['combined_confidence'])
            results[concept] = {
                'known': False,
                'confidence': assessment['combined_confidence'],
                'state': assessment['state'],
            }
        
        print("\n  üìä Testing on KNOWN concepts (should have HIGH confidence):")
        known_scores = []
        for question, concept in known_questions:
            hidden = self.get_hidden_state(question)
            assessment = self.metacognition.assess(hidden, question)
            
            print(f"    Q: \"{question}\"")
            print(f"       Combined Conf: {assessment['combined_confidence']:.3f} | "
                  f"State: {assessment['state']} | Memory: {assessment['concept_found']}")
            
            known_scores.append(assessment['combined_confidence'])
            results[concept] = {
                'known': True,
                'confidence': assessment['combined_confidence'],
                'state': assessment['state'],
            }
        
        # Analysis
        avg_unknown = sum(unknown_scores) / len(unknown_scores)
        avg_known = sum(known_scores) / len(known_scores)
        
        print("\n" + "‚îÄ" * 60)
        print("  METACOGNITION RESULTS:")
        print(f"    Unknown avg confidence: {avg_unknown:.3f}")
        print(f"    Known avg confidence:   {avg_known:.3f}")
        
        # Success if known > unknown with significant margin
        success = avg_known > avg_unknown + 0.2
        
        if success:
            print(f"\n  ‚úÖ SUCCESS! Brain correctly distinguishes known from unknown!")
            print(f"     Difference: {avg_known - avg_unknown:.3f} (> 0.2 threshold)")
        else:
            print(f"\n  ‚ö†Ô∏è Metacognition needs more calibration")
            print(f"     Difference: {avg_known - avg_unknown:.3f}")
        
        results['summary'] = {
            'avg_unknown': avg_unknown,
            'avg_known': avg_known,
            'success': success,
        }
        
        return results
    
    # =====================================
    # TEST 2: REASONING
    # =====================================
    
    def test_reasoning(self) -> Dict:
        """
        Test: Can the brain perform simple inference?
        
        If apple=blue and blueberry=blue, they share the color blue.
        """
        print("\n" + "‚ïê" * 80)
        print("  TEST 2: REASONING & INFERENCE")
        print("  Can the brain connect related concepts?")
        print("‚ïê" * 80)
        
        results = {}
        
        # Learn related concepts
        print("\n  üìö Setting up:  apple=blue, banana=blue, orange=blue")
        
        related_concepts = [
            ("apple", "blue"),
            ("banana", "blue"),
            ("orange", "blue"),
        ]
        
        for concept, value in related_concepts:
            self.learn_concept(concept, value)
            print(f"    ‚úì Learned: {concept} = {value}")
        
        # Test: "What color are fruits?"
        test_question = "What color are fruits?"
        
        print(f"\n  üß† Reasoning test: \"{test_question}\"")
        
        # Get probabilities for different colors
        colors = ["blue", "red", "green", "yellow"]
        probs = {}
        for color in colors:
            prob = self.get_probability(test_question, color)
            probs[color] = prob
        
        print(f"    Probabilities:")
        for color, prob in sorted(probs.items(), key=lambda x: -x[1]):
            status = "‚Üê Expected" if color == "blue" else ""
            print(f"      {color}: {prob:.4f} {status}")
        
        # Check if blue has highest probability
        max_color = max(probs, key=probs.get)
        success = max_color == "blue"
        
        print(f"\n    Result: {'‚úÖ CORRECT!' if success else '‚ùå Incorrect'} (Predicted: {max_color})")
        
        results['category_inference'] = {
            'question': test_question,
            'probs': probs,
            'predicted': max_color,
            'expected': "blue",
            'success': success,
        }
        
        return results
    
    # =====================================
    # TEST 3: SELF-CORRECTION
    # =====================================
    
    def test_self_correction(self) -> Dict:
        """
        Test: Can the brain correct its own mistakes?
        
        1. Make a "wrong" prediction
        2. Receive feedback
        3. Learn the correct answer
        4. Verify correction
        """
        print("\n" + "‚ïê" * 80)
        print("  TEST 3: SELF-CORRECTION")
        print("  Can the brain fix its own mistakes?")
        print("‚ïê" * 80)
        
        results = {}
        
        # Save original weights
        original_weights = self.brain.output_projection.weight.data.clone()
        
        # Choose a concept the model gets "wrong"
        test_concept = "moon"
        wrong_answer = "yellow"  # Model might predict this
        correct_answer = "silver"  # What we want it to learn
        
        question = "What color is the moon?"
        template = "The moon in this reality is always {COLOR}."
        
        print(f"\n  Question: \"{question}\"")
        
        # Initial prediction
        initial_probs = {
            "yellow": self.get_probability(question, "yellow"),
            "white": self.get_probability(question, "white"),
            "silver": self.get_probability(question, "silver"),
            "gray": self.get_probability(question, "gray"),
        }
        
        print(f"\n  BEFORE correction:")
        for color, prob in sorted(initial_probs.items(), key=lambda x: -x[1]):
            print(f"    {color}: {prob:.4f}")
        
        initial_best = max(initial_probs, key=initial_probs.get)
        print(f"    ‚Üí Initial prediction: {initial_best}")
        
        # Correction phase - teach the correct answer
        print(f"\n  ‚ö° Applying correction: moon = silver")
        
        # Learn the correction
        INCEPTION_TEMPLATES["moon"] = template
        self.learn_concept("moon", correct_answer)
        
        # After correction
        corrected_probs = {
            "yellow": self.get_probability(question, "yellow"),
            "white": self.get_probability(question, "white"),
            "silver": self.get_probability(question, "silver"),
            "gray": self.get_probability(question, "gray"),
        }
        
        print(f"\n  AFTER correction:")
        for color, prob in sorted(corrected_probs.items(), key=lambda x: -x[1]):
            change = prob - initial_probs[color]
            print(f"    {color}: {prob:.4f} (Œî={change:+.4f})")
        
        corrected_best = max(corrected_probs, key=corrected_probs.get)
        print(f"    ‚Üí New prediction: {corrected_best}")
        
        # Check if correction worked
        silver_increased = corrected_probs["silver"] > initial_probs["silver"]
        success = corrected_best == correct_answer or silver_increased
        
        print(f"\n  Result: {'‚úÖ CORRECTION SUCCESSFUL!' if success else '‚ùå Correction failed'}")
        
        # Restore weights
        self.brain.output_projection.weight.data.copy_(original_weights)
        
        results['moon_correction'] = {
            'initial_prediction': initial_best,
            'corrected_prediction': corrected_best,
            'expected': correct_answer,
            'silver_increased': silver_increased,
            'success': success,
        }
        
        return results
    
    # =====================================
    # FULL BENCHMARK
    # =====================================
    
    def run_full_benchmark(self):
        """Run all ASI benchmark tests."""
        
        print("\n" + "‚ïê" * 80)
        print("‚ïë" + " " * 78 + "‚ïë")
        print("‚ïë" + "  üß† N≈åKAI v0.8: TOWARDS ASI".center(78) + "‚ïë")
        print("‚ïë" + "  Target: 90%+ AGI Score".center(78) + "‚ïë")
        print("‚ïë" + " " * 78 + "‚ïë")
        print("‚ïê" * 80)
        
        if not self.load_model():
            print("\n  ‚ùå Failed to load model")
            return
        
        all_results = {}
        scores = []
        
        # Test 1: Enhanced Metacognition
        all_results['metacognition'] = self.test_metacognition()
        score1 = 1.0 if all_results['metacognition'].get('summary', {}).get('success', False) else 0.5
        scores.append(score1)
        
        # Test 2: Reasoning
        all_results['reasoning'] = self.test_reasoning()
        reasoning_results = all_results['reasoning'].get('category_inference', {})
        score2 = 1.0 if reasoning_results.get('success', False) else 0.0
        scores.append(score2)
        
        # Test 3: Self-Correction
        all_results['self_correction'] = self.test_self_correction()
        correction_results = all_results['self_correction'].get('moon_correction', {})
        score3 = 1.0 if correction_results.get('success', False) else 0.5
        scores.append(score3)
        
        # Calculate final score
        agi_score = sum(scores) / len(scores)
        
        # Summary
        print("\n" + "‚ïê" * 80)
        print("  ASI BENCHMARK SUMMARY")
        print("‚ïê" * 80)
        
        print(f"\n  1. METACOGNITION:    {'‚úÖ PASS' if score1 == 1.0 else '‚ö†Ô∏è PARTIAL'}")
        print(f"  2. REASONING:        {'‚úÖ PASS' if score2 == 1.0 else '‚ùå NEEDS WORK'}")
        print(f"  3. SELF-CORRECTION:  {'‚úÖ PASS' if score3 == 1.0 else '‚ö†Ô∏è PARTIAL'}")
        
        print(f"\n  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
        print(f"      AGI/ASI CAPABILITY SCORE: {agi_score:.1%}")
        print(f"  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
        
        if agi_score >= 0.9:
            print(f"\n  üéâ EXCELLENT! Approaching ASI capabilities!")
        elif agi_score >= 0.75:
            print(f"\n  ‚úÖ GOOD! Strong AGI capabilities demonstrated!")
        elif agi_score >= 0.5:
            print(f"\n  ‚ö†Ô∏è Making progress towards AGI.")
        else:
            print(f"\n  ‚ùå More work needed on core capabilities.")
        
        # Save memory at end
        self.memory.save()
        
        print("\n" + "‚ïê" * 80)
        print("  END OF ASI BENCHMARK")
        print("‚ïê" * 80 + "\n")
        
        self.results = all_results
        return all_results


# ============================================
# MAIN
# ============================================

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="N≈çkai v0.8 - ASI Benchmark")
    parser.add_argument("--checkpoint_dir", type=str, default="checkpoints")
    parser.add_argument("--mode", type=str, default="full",
                       choices=["meta", "reason", "correct", "full"])
    parser.add_argument("--hebbian_lr", type=float, default=0.06)
    parser.add_argument("--repetitions", type=int, default=20)
    
    args = parser.parse_args()
    
    # Auto-detect model
    checkpoint_dir = Path(args.checkpoint_dir)
    model_file = "brain_epoch_5.pt"
    for candidate in ["brain_epoch_5.pt", "brain_best.pt"]:
        if (checkpoint_dir / candidate).exists():
            model_file = candidate
            break
    
    config = ExperimentV08Config(
        checkpoint_dir=args.checkpoint_dir,
        model_file=model_file,
        mode=args.mode,
        hebbian_lr=args.hebbian_lr,
        num_repetitions=args.repetitions,
    )
    
    benchmark = ASIBenchmark(config)
    
    if args.mode == "meta":
        if benchmark.load_model():
            benchmark.test_metacognition()
    elif args.mode == "reason":
        if benchmark.load_model():
            benchmark.test_reasoning()
    elif args.mode == "correct":
        if benchmark.load_model():
            benchmark.test_self_correction()
    else:
        benchmark.run_full_benchmark()


if __name__ == "__main__":
    main()
